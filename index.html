<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="theme-color" content="#f8f5ec"><meta name="msapplication-navbutton-color" content="#f8f5ec"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec"><meta name="description" content="励志考研"><link rel="alternate" href="/atom.xml" title="MrsW6"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=2.6.0"><link rel="canonical" href="http://yoursite.com/"><link rel="stylesheet" type="text/css" href="/css/style.css?v=2.6.0"><link rel="stylesheet" type="text/css" href="/lib/fancybox/jquery.fancybox.css"><script id="baidu_push">!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}()</script><title>MrsW6</title></head><body><div id="mobile-navbar" class="mobile-navbar"><div class="mobile-header-logo"><a href="/." class="logo">MrsW6</a></div><div class="mobile-navbar-icon"><span></span> <span></span> <span></span></div></div><nav id="mobile-menu" class="mobile-menu slideout-menu"><ul class="mobile-menu-list"><a href="/"><li class="mobile-menu-item">主页</li></a><a href="/archives/"><li class="mobile-menu-item">归档</li></a><a href="/about"><li class="mobile-menu-item">关于</li></a></ul></nav><div class="container" id="mobile-panel"><header id="header" class="header"><div class="logo-wrapper"><a href="/." class="logo">MrsW6</a></div><nav class="site-navbar"><ul id="menu" class="menu"><li class="menu-item"><a class="menu-item-link" href="/">主页</a></li><li class="menu-item"><a class="menu-item-link" href="/archives/">归档</a></li><li class="menu-item"><a class="menu-item-link" href="/about">关于</a></li></ul></nav></header><main id="main" class="main"><div class="content-wrapper"><div id="content" class="content"><section id="posts" class="posts"><article class="post"><header class="post-header"><h1 class="post-title"><a class="post-link" href="/2018/02/12/2018-2019学习计划/">2018上半年学习计划</a></h1><div class="post-meta"><span class="post-time">2018-02-12</span><div class="post-category"><a href="/categories/随笔/">随笔</a></div></div></header><div class="post-content"><p>未来的这两年，不会再涉及新的语言，主要就是Java和Python。C++的学习主要是考研和数据结构的学习<br></p><div class="read-more"><a href="/2018/02/12/2018-2019学习计划/" class="read-more-link">阅读更多</a></div></div></article><article class="post"><header class="post-header"><h1 class="post-title"><a class="post-link" href="/2018/02/11/DFS入门/">DFS入门</a></h1><div class="post-meta"><span class="post-time">2018-02-11</span><div class="post-category"><a href="/categories/Algorithm/">Algorithm</a></div></div></header><div class="post-content"><p>DFS：深度优先搜索<br>题意：n件物品，每件物品重量为w[i]，价值为c[i]，背包的最大承重为v，在不超过重量v的前提下，让背包中，物品的价格之和最大，求最大价值！<br>在面对每一个选择的时候，可以选择，也可以不选择，dfs之后得出来的结果一定是最大值，dfs其实就是暴力搜索<br></p><div class="read-more"><a href="/2018/02/11/DFS入门/" class="read-more-link">阅读更多</a></div></div></article><article class="post"><header class="post-header"><h1 class="post-title"><a class="post-link" href="/2018/02/03/独立完成的Python爬虫项目/">Python-当当网信息提取</a></h1><div class="post-meta"><span class="post-time">2018-02-03</span><div class="post-category"><a href="/categories/Python/">Python</a></div></div></header><div class="post-content"><p>基于爬取淘宝网商品信息爬虫实例，爬取当当网图书信息，读取用户输入的信息，进行搜索，翻页等功能的实现，主要用到了requests和re库，其实就是最常用的代码框架，项目主我的缺陷主要是对正则表达式不熟悉，不会使用增则表达式，对Python语法不熟悉，应加强这两个方面的应用！<br></p><div class="read-more"><a href="/2018/02/03/独立完成的Python爬虫项目/" class="read-more-link">阅读更多</a></div></div></article><article class="post"><header class="post-header"><h1 class="post-title"><a class="post-link" href="/2018/02/02/爬取淘宝网商品信息/">Python-爬取淘宝网商品信息</a></h1><div class="post-meta"><span class="post-time">2018-02-02</span><div class="post-category"><a href="/categories/Python/">Python</a></div></div></header><div class="post-content"><p>简单爬虫和format方法的应用</p><div class="read-more"><a href="/2018/02/02/爬取淘宝网商品信息/" class="read-more-link">阅读更多</a></div></div></article><article class="post"><header class="post-header"><h1 class="post-title"><a class="post-link" href="/2018/02/02/Python爬虫-正则表达式/">Python-正则表达式</a></h1><div class="post-meta"><span class="post-time">2018-02-02</span><div class="post-category"><a href="/categories/Python/">Python</a></div></div></header><div class="post-content"><p>Python正则表达式的使用规则</p><div class="read-more"><a href="/2018/02/02/Python爬虫-正则表达式/" class="read-more-link">阅读更多</a></div></div></article><article class="post"><header class="post-header"><h1 class="post-title"><a class="post-link" href="/2018/01/31/Python-“爬取中国大学排名/">Python-爬取中国大学排名</a></h1><div class="post-meta"><span class="post-time">2018-01-31</span><div class="post-category"><a href="/categories/Python/">Python</a></div></div></header><div class="post-content"><p>得到页面信息并使用beautifusoup库解析</p><div class="read-more"><a href="/2018/01/31/Python-“爬取中国大学排名/" class="read-more-link">阅读更多</a></div></div></article><article class="post"><header class="post-header"><h1 class="post-title"><a class="post-link" href="/2018/01/31/Python爬虫③/">Python爬虫③</a></h1><div class="post-meta"><span class="post-time">2018-01-31</span><div class="post-category"><a href="/categories/Python/">Python</a></div></div></header><div class="post-content"><p>使用Beautiful Soup提供一些简单的、python式的函数用来处理导航、搜索、修改分析树等功能。</p><div class="read-more"><a href="/2018/01/31/Python爬虫③/" class="read-more-link">阅读更多</a></div></div></article><article class="post"><header class="post-header"><h1 class="post-title"><a class="post-link" href="/2018/01/31/Python爬虫②/">Python爬虫②</a></h1><div class="post-meta"><span class="post-time">2018-01-31</span><div class="post-category"><a href="/categories/Python/">Python</a></div></div></header><div class="post-content"><p>Python爬虫的基本实现和基本框架</p><div class="read-more"><a href="/2018/01/31/Python爬虫②/" class="read-more-link">阅读更多</a></div></div></article><article class="post"><header class="post-header"><h1 class="post-title"><a class="post-link" href="/2018/01/30/Python爬虫①/">Python爬虫①</a></h1><div class="post-meta"><span class="post-time">2018-01-30</span><div class="post-category"><a href="/categories/Python/">Python</a></div></div></header><div class="post-content"><h1 id="requests"><a href="#requests" class="headerlink" title="requests"></a>requests</h1><p><a href="https://www.jianshu.com/p/d78982126318" target="_blank" rel="noopener">Python Request库入门</a></p><h2 id="requests的安装"><a href="#requests的安装" class="headerlink" title="requests的安装"></a>requests的安装</h2><p>requests库是Python第三方库最强大的爬虫库<br>以管理员身份运行cmd，输入pip install requests即可，然后运行pycharm导入<br>随便写一个Python程序</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">r = requests.get(<span class="string">"http://www.baidu.com"</span>)</span><br><span class="line">print(r.status_code)</span><br><span class="line">print(type(r))</span><br><span class="line">r.encoding = <span class="string">'utf-8'</span></span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure>
<h2 id="raise-for-status-方法"><a href="#raise-for-status-方法" class="headerlink" title="raise_for_status()方法"></a>raise_for_status()方法</h2><p>调用raise_for_status()方法，如果r.status_code的返回值是200，则程序正常执行，如果不是两百，那么就会抛出一个requests.HTTPError异常</p>
<h2 id="常用代码框架"><a href="#常用代码框架" class="headerlink" title="常用代码框架"></a>常用代码框架</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getHTMLText</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        r = requests.get(url,timeout = <span class="number">30</span>)</span><br><span class="line">        r.raise_for_status()</span><br><span class="line">        r.encoding = r.apparent_encoding</span><br><span class="line">        <span class="keyword">return</span> r.text</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"产生异常"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    url = <span class="string">"https://www.icourse163.org"</span></span><br><span class="line">    print(getHTMLText(url))</span><br></pre></td></tr></table></figure>
<h1 id="HTTP"><a href="#HTTP" class="headerlink" title="HTTP"></a>HTTP</h1><p>http协议：超文本传输协议，是一个基于响应与请求模式的无状态的应用层协议<br>请求与响应：用户发出请求，服务器响应</p>
<h1 id="计算多次连续访问同一页面所需要的时间"><a href="#计算多次连续访问同一页面所需要的时间" class="headerlink" title="计算多次连续访问同一页面所需要的时间"></a>计算多次连续访问同一页面所需要的时间</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    url = <span class="string">'https://www.icourse163.org/learn/BIT-1001870001?tid=1002236011#/learn/content?type=detail&amp;id=1002993601&amp;cid=1003503362'</span></span><br><span class="line">    n = (int)(input(<span class="string">"请输入需要爬取页面的次数： "</span>))</span><br><span class="line">    t1 = time.time()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,n+<span class="number">1</span>):</span><br><span class="line">        getHTMLText(url)</span><br><span class="line">        print(<span class="string">'第%d次爬取成功'</span>%i)</span><br><span class="line">    t2 = time.time()</span><br><span class="line">    t = t2 - t1</span><br><span class="line">    print(<span class="string">'连续访问%d个页面需要的时间是%f秒'</span>% (n,t))</span><br><span class="line"></span><br><span class="line">main()</span><br></pre></td></tr></table></figure>
<h1 id="模拟浏览器发出请求"><a href="#模拟浏览器发出请求" class="headerlink" title="模拟浏览器发出请求"></a>模拟浏览器发出请求</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">url = <span class="string">'https://www.amazon.cn/gp/product/B0058XHR28?pf_rd_p=8e368709-9a2f-4695-abee-10147fab0c6e&amp;pf_rd_s=merchandised-search-7&amp;pf_rd_t=101&amp;pf_rd_i=1841388071&amp;pf_rd_m=A1AJ19PSB66TGU&amp;pf_rd_r=JKH9RF6AFN0YGT4GY92N&amp;ref=cn_ags_floor_hotasin_1841388071_mobile-1'</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    kv = &#123;<span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0'</span>&#125;</span><br><span class="line">    r = requests.get(url,timeout = <span class="number">10</span>,headers = kv)</span><br><span class="line">    r.raise_for_status()</span><br><span class="line">    r.encoding = r.apparent_encoding</span><br><span class="line">    print(r.request.headers)</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    print(<span class="string">'失败'</span>)</span><br></pre></td></tr></table></figure>
<p>通过修改头部信息，从而模拟浏览器访问页面</p>
<h1 id="百度关键词搜索"><a href="#百度关键词搜索" class="headerlink" title="百度关键词搜索"></a>百度关键词搜索</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">kv = &#123;<span class="string">'wd'</span>:<span class="string">'python'</span>&#125;</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line"></span><br><span class="line">    r = requests.get(<span class="string">'https://www.baidu.com/s'</span>,params = kv)</span><br><span class="line">    r.raise_for_status()</span><br><span class="line">    r.encoding = r.apparent_encoding</span><br><span class="line">    print(r.request.url)</span><br><span class="line">    print(len(r.text))</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    print(<span class="string">'爬取失败'</span>)</span><br></pre></td></tr></table></figure>
<h1 id="从网上爬取图片并下载下来"><a href="#从网上爬取图片并下载下来" class="headerlink" title="从网上爬取图片并下载下来"></a>从网上爬取图片并下载下来</h1><p>不规范版本：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">path = <span class="string">"D:/abc.jpg"</span></span><br><span class="line">url = <span class="string">'http://imgsrc.baidu.com/forum/pic/item/e420a54bd11373f027775715a40f4bfbfaed0456.jpg'</span></span><br><span class="line">r = requests.get(url)</span><br><span class="line"><span class="comment"># print(r.status_code)</span></span><br><span class="line"><span class="keyword">with</span> open(path,<span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(r.content)</span><br></pre></td></tr></table></figure>
<p>规范：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="comment">#图片地址</span></span><br><span class="line">    url = <span class="string">'http://imgsrc.baidu.com/forum/pic/item/e420a54bd11373f027775715a40f4bfbfaed0456.jpg'</span></span><br><span class="line">    <span class="comment">#根目录</span></span><br><span class="line">    root = <span class="string">'D:/'</span></span><br><span class="line">    <span class="comment">#储存的路径</span></span><br><span class="line">    path = root + url.split(<span class="string">'/'</span>)[<span class="number">-1</span>]</span><br><span class="line">    r = requests.get(url)</span><br><span class="line">    <span class="keyword">with</span> open(path,<span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(r.content)</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    print(<span class="string">"出错啦"</span>)</span><br></pre></td></tr></table></figure>
<h1 id="ip地址查询"><a href="#ip地址查询" class="headerlink" title="ip地址查询"></a>ip地址查询</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line"></span><br><span class="line">    url = <span class="string">'http://m.ip138.com/ip.asp?ip='</span></span><br><span class="line">    r =requests.get(url + <span class="string">'202.204.80.112'</span>)</span><br><span class="line">    print(r.text[<span class="number">-500</span>:])</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    print(<span class="string">"出错啦"</span>)</span><br></pre></td></tr></table></figure>
<h1 id="下载一个MOOC的视频"><a href="#下载一个MOOC的视频" class="headerlink" title="下载一个MOOC的视频"></a>下载一个MOOC的视频</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#爬一个慕课网的视频</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    url = <span class="string">'https://v.stu.126.net/mooc-video/nos/mp4/2017/02/28/1005855330_c19061df10ee4cd69496dba4292e9ea3_shd.mp4?ak=285ea3e4dadf82f0450503b24518d5679cdf68ccbb7c2011693b179b27153140698691431388c23472d118fc0d79340ceff6a55d15491982836e42383e13363eec6958477c8e90f2fc976eed060cb9b81e46d140b7b30f910299bee40b26a5c2d9e1e3c44585e5de5b539ccdbe8423a821b91261e44e538d2765af73aa008299a7f5cc498d43fe59a782bc973c30c066b767da1f870bc890754ea6567cb70ca9830b67d08aac63e1ac0c534090a89323f6fd9d4e9030d5d8cb0cb4b5fcb8e77c'</span></span><br><span class="line">    r = requests.get(url)</span><br><span class="line">    path = <span class="string">'D:/123.mp4'</span></span><br><span class="line">    <span class="keyword">with</span> open(path,<span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(r.content)</span><br><span class="line">    print(<span class="string">"下载完毕"</span>)</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    print(<span class="string">"XXX"</span>)</span><br></pre></td></tr></table></figure>
<h1 id="BeautifulSoup库的使用"><a href="#BeautifulSoup库的使用" class="headerlink" title="BeautifulSoup库的使用"></a>BeautifulSoup库的使用</h1><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>以管理员身份运行cmd，输入pip install BeautifunSoup4,然后在pycharm导入相应的模块就可以了</p>
<h2 id="运行代码"><a href="#运行代码" class="headerlink" title="运行代码"></a>运行代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">r = requests.get(<span class="string">"http://jw.qdu.edu.cn/homepage/index.do"</span>)</span><br><span class="line">demo = r.text</span><br><span class="line">soup = BeautifulSoup(demo,<span class="string">"html.parser"</span>)</span><br><span class="line">print(soup.prettify())</span><br></pre></td></tr></table></figure>
<p>soup = BeautifulSoup(demo,”html.parser”)的两个参数：<br>第一个参数是html的一个格式<br>第二个参数是html的解析器</p>
<h2 id="基本元素"><a href="#基本元素" class="headerlink" title="基本元素"></a>基本元素</h2><p>BeautifulSoup库是解析，遍历，维护标签树的功能库</p>
<p>1.Tag<br>2.Name<br>3.Attributes<br>4.Comment<br>5.NavigableString</p>
<h3 id="获得标签信息"><a href="#获得标签信息" class="headerlink" title="获得标签信息"></a>获得标签信息</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#获得a标签</span></span><br><span class="line">tag = soup.a</span><br><span class="line"><span class="comment">#获得a的名字，当然就是a</span></span><br><span class="line"><span class="keyword">print</span>（soup.a.name）</span><br><span class="line"><span class="comment">#获得标签属性</span></span><br><span class="line"><span class="keyword">print</span>（soup.a.attrs）</span><br><span class="line"><span class="comment">#获得标签之间的字符串</span></span><br><span class="line">print(soup.a.string)</span><br></pre></td></tr></table></figure>
<h3 id="prettify"><a href="#prettify" class="headerlink" title=".prettify()"></a>.prettify()</h3><p>能够更加有好的显示html文件，包括换行符缩进等等</p>
<h2 id="查找一个HTML页面a标签href后的内容"><a href="#查找一个HTML页面a标签href后的内容" class="headerlink" title="查找一个HTML页面a标签href后的内容"></a>查找一个HTML页面a标签href后的内容</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">r = requests.get(<span class="string">"https://www.icourse163.org/learn/BIT-1001870001?tid=1002236011"</span>)</span><br><span class="line">demo = r.text</span><br><span class="line">soup = BeautifulSoup(demo,<span class="string">"html.parser"</span>)</span><br><span class="line"><span class="keyword">for</span> link <span class="keyword">in</span> soup.find_all(<span class="string">'a'</span>):</span><br><span class="line">    <span class="keyword">if</span> link.get(<span class="string">'href'</span>) == <span class="keyword">None</span>:</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        print(link.get(<span class="string">'href'</span>))</span><br></pre></td></tr></table></figure>

        
      
    </div>

    

    

  </article>

    
      
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          <a class="post-link" href="/2018/01/30/Python基础③/">Python基础③</a>
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2018-01-30
        </span>
        
          <div class="post-category">
            
              <a href="/categories/Python/">Python</a>
            
          </div>
        
        
      </div>
    </header>

    
    

    <div class="post-content">
      
        
        
          
        

        
          <p>有关Python函数的相关讨论</p>
          <div class="read-more">
            <a href="/2018/01/30/Python基础③/" class="read-more-link">阅读更多</a>
          </div>
        
      
    </div>

    

    

  </article>

    
  </section>

  
  <nav class="pagination">
    
    
      <a class="next" href="/page/2/">
        <span class="next-text">下一页</span>
        <i class="iconfont icon-right"></i>
      </a>
    
  </nav>


          </div>
          

        </div>
      </main>

      <footer id="footer" class="footer">

  <div class="social-links">
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
    
    
      <a href="/atom.xml" class="iconfont icon-rss" title="rss"></a>
    
  </div>


<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://mrsw6.github.io/">MrsW6😀</a> 强力驱动
  </span>
  <span class="division">|</span>
  

  <span class="copyright-year">
    
    &copy; 
     
      2017 - 
    
    2018

    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">MrsW6</span>
  </span>
</div>

      </footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>

    


    
  





  
    <script type="text/javascript" src="/lib/jquery/jquery-3.1.1.min.js"></script>
  

  
    <script type="text/javascript" src="/lib/slideout/slideout.js"></script>
  

  
    <script type="text/javascript" src="/lib/fancybox/jquery.fancybox.pack.js"></script>
  


    <script type="text/javascript" src="/js/src/even.js?v=2.6.0"></script>
<script type="text/javascript" src="/js/src/bootstrap.js?v=2.6.0"></script></body></html>